kafka:
  rest:
    user: kafka-rest
    group: kafka-rest
    heap: -Xmx1000M
    logdir: /var/log/kafka-rest
  broker:
    user: cp-kafka
    group: cp-kafka
    config_file: /etc/kafka/server.properties
    logging_config_file: /etc/kafka/server.logging.properties
    systemd_file: /usr/lib/systemd/system/confluent-kafka.service
    service_name: confluent-kafka
    datadir:
      - /var/lib/kafka
    environment:
      KAFKA_HEAP_OPTS: "-Xmx1000M"
      LOG_DIR: /var/log/kafka
    systemd:
      enabled: yes
      state: started
      LimitNOFILE: 128000
      TimeoutStopSec: 300
      RestartSec: 5
    config:
      confluent.support.customer.id: anonymous
      confluent.support.metrics.enable: true
      group.initial.rebalance.delay.ms: 0
      log.retention.check.interval.ms: 300000
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      num.io.threads: 16
      num.network.threads: 8
      num.partitions: 1
      num.recovery.threads.per.data.dir: 2
      offsets.topic.replication.factor: 3
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      socket.send.buffer.bytes: 102400
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
      zookeeper.connection.timeout.ms: 6000
      metric.reporters: io.confluent.metrics.reporter.ConfluentMetricsReporter
      confluent.metrics.reporter.bootstrap.servers: "{{inventory_hostname}}:9092"
  connect:
    user: cp-kafka
    group: cp-kafka
    distributed:
      config_file: /etc/kafka/connect-distributed.properties
      logging_config_file: /etc/kafka/connect-distributed.logging.properties
      systemd_file: /usr/lib/systemd/system/confluent-connect-distributed.service
      service_name: confluent-connect-distributed
      plugin_path:
        - /usr/share/java
      config:
        consumer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
        producer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
        config.storage.replication.factor: 3
        config.storage.topic: connect-configs
        group.id: connect-cluster
        internal.key.converter: org.apache.kafka.connect.json.JsonConverter
        internal.key.converter.schemas.enable: false
        internal.value.converter: org.apache.kafka.connect.json.JsonConverter
        internal.value.converter.schemas.enable: false
        offset.flush.interval.ms: 10000
        offset.storage.replication.factor: 3
        offset.storage.topic: connect-offsets
        status.storage.replication.factor: 3
        status.storage.topic: connect-status
        key.converter: io.confluent.connect.avro.AvroConverter
        value.converter: io.confluent.connect.avro.AvroConverter
      environment:
        KAFKA_HEAP_OPTS: "-Xmx1000M"
        LOG_DIR: /var/log/connect-distributed
      systemd:
        enabled: yes
        state: started
        LimitNOFILE: 128000
        TimeoutStopSec: 300
        RestartSec: 5
    standalone:
      data_dir: /var/lib/connect-standalone
      plugin_path:
        - /usr/share/java
      environment:
        KAFKA_HEAP_OPTS: "-Xmx1000M"
        LOG_DIR: /var/log/connect-standalone
      config:
        consumer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
        producer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
        internal.key.converter: org.apache.kafka.connect.json.JsonConverter
        internal.key.converter.schemas.enable: false
        internal.value.converter: org.apache.kafka.connect.json.JsonConverter
        internal.value.converter.schemas.enable: false
        offset.flush.interval.ms: 10000
        key.converter: io.confluent.connect.avro.AvroConverter
        value.converter: io.confluent.connect.avro.AvroConverter
zookeeper:
  user: cp-kafka
  group: cp-kafka
  config_file: /etc/kafka/zookeeper.properties
  logging_config_file: /etc/kafka/zookeeper.logging.properties
  systemd_file: /usr/lib/systemd/system/confluent-zookeeper.service
  service_name: confluent-zookeeper
  config:
    clientPort: 2181
    maxClientCnxns: 0
    initLimit: 5
    syncLimit: 2
    autopurge.snapRetainCount: 10
    autopurge.purgeInterval: 1
    dataDir: /var/lib/zookeeper
  environment:
    KAFKA_HEAP_OPTS: "-Xmx1000M"
    LOG_DIR: /var/log/zookeeper
  systemd:
    enabled: yes
    state: started
    LimitNOFILE: 128000
    TimeoutStopSec: 300
    RestartSec: 5
schema:
  registry:
    user: cp-schema-registry
    group: cp-schema-registry
    config_file: /etc/kafka/schema-registry.properties
    logging_config_file: /etc/kafka/schema-registry.logging.properties
    systemd_file: /usr/lib/systemd/system/confluent-schema-registry.service
    service_name: confluent-schema-registry
    config:
      listeners: http://0.0.0.0:8081
      kafkastore.topic: _schemas
      debug: false
    environment:
      SCHEMA_REGISTRY_HEAP_OPTS: "-Xmx1000M"
      LOG_DIR: /var/log/schema-registry
    systemd:
      enabled: yes
      state: started
      LimitNOFILE: 128000
      TimeoutStopSec: 300
      RestartSec: 5
confluent:
  package_name: confluent-platform-2.11
  repository:
    debian:
    redhat:
      main:
        baseurl: https://packages.confluent.io/rpm/4.0
        gpgcheck: 1
        gpgkey: https://packages.confluent.io/rpm/4.0/archive.key
        enabled: 1
      dist:
        baseurl: https://packages.confluent.io/rpm/4.0/7
        gpgcheck: 1
        gpgkey:  https://packages.confluent.io/rpm/4.0/archive.key
        enabled: 1
  control:
    center:
      user: cp-control-center
      group: cp-control-center
      config_file: /etc/confluent-control-center/control-center.properties
      logging_config_file: /etc/confluent-control-center/zookeeper.logging.properties
      systemd_file: /usr/lib/systemd/system/confluent-control-center.service
      service_name: confluent-control-center
      data_dir: /var/lib/confluent-control-center
      config:
        confluent.controlcenter.streams.num.stream.threads: 8
      environment:
        CONTROL_CENTER_HEAP_OPTS: "-Xmx1000M"
        LOG_DIR: /var/log/confluent-control-center
      systemd:
        enabled: yes
        state: started
        LimitNOFILE: 128000
        TimeoutStopSec: 300
        RestartSec: 5

# service, user
#confluent-schema-registry, cp-schema-registry
#confluent-kafka-rest, cp-kafka-rest
#confluent-control-center, cp-control-center
#confluent-kafka-connect, cp-kafka-connect
#confluent-kafka, cp-kafka
#confluent-zookeeper, cp-kafka   <-- Take note!
#confluent-ksql, cp-ksql